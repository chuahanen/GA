{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 3\n",
    "\n",
    "### Regression and Classification with the Ames Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "You have just joined a new \"full stack\" real estate company in Ames, Iowa. The strategy of the firm is two-fold:\n",
    "- Own the entire process from the purchase of the land all the way to sale of the house, and anything in between.\n",
    "- Use statistical analysis to optimize investment and maximize return.\n",
    "\n",
    "The company is still small, and though investment is substantial the short-term goals of the company are more oriented towards purchasing existing houses and flipping them as opposed to constructing entirely new houses. That being said, the company has access to a large construction workforce operating at rock-bottom prices.\n",
    "\n",
    "This project uses the [Ames housing data recently made available on kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Estimating the value of homes from fixed characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "Your superiors have outlined this year's strategy for the company:\n",
    "1. Develop an algorithm to reliably estimate the value of residential houses based on *fixed* characteristics.\n",
    "2. Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.\n",
    "3. Evaluate the mean dollar value of different renovations.\n",
    "\n",
    "Then we can use that to buy houses that are likely to sell for more than the cost of the purchase plus renovations.\n",
    "\n",
    "Your first job is to tackle #1. You have a dataset of housing sale data with a huge amount of features identifying different aspects of the house. The full description of the data features can be found in a separate file:\n",
    "\n",
    "    housing.csv\n",
    "    data_description.txt\n",
    "    \n",
    "You need to build a reliable estimator for the price of the house given characteristics of the house that cannot be renovated. Some examples include:\n",
    "- The neighborhood\n",
    "- Square feet\n",
    "- Bedrooms, bathrooms\n",
    "- Basement and garage space\n",
    "\n",
    "and many more. \n",
    "\n",
    "Some examples of things that **ARE renovate-able:**\n",
    "- Roof and exterior features\n",
    "- \"Quality\" metrics, such as kitchen quality\n",
    "- \"Condition\" metrics, such as condition of garage\n",
    "- Heating and electrical components\n",
    "\n",
    "and generally anything you deem can be modified without having to undergo major construction on the house.\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Perform any cleaning, feature engineering, and EDA you deem necessary.\n",
    "- Be sure to remove any houses that are not residential from the dataset.\n",
    "- Identify **fixed** features that can predict price.\n",
    "- Train a model on pre-2010 data and evaluate its performance on the 2010 houses.\n",
    "- Characterize your model. How well does it perform? What are the best estimates of price?\n",
    "\n",
    "> **Note:** The EDA and feature engineering component to this project is not trivial! Be sure to always think critically and creatively. Justify your actions! Use the data description file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'./housing.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bffc15f33c91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhouse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./housing.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'./housing.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "house = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing non-residential property\n",
    "house = house[house['MSZoning'].isin(['FV','RH','RL','RP','RM'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns w many null values\n",
    "house.drop(['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house.drop(['Id','SalePrice'],axis=1)\n",
    "y = house['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping non-fixed features\n",
    "X.drop(['OverallQual', 'OverallCond','RoofStyle','RoofMatl', 'Exterior1st', 'Exterior2nd',\\\n",
    "'MasVnrType', 'MasVnrArea','ExterQual', 'ExterCond', 'BsmtCond', 'BsmtExposure',\\\n",
    "'BsmtFinType1', 'BsmtFinType2', 'BsmtUnfSF','Heating', 'HeatingQC','CentralAir',\\\n",
    "'Electrical', 'KitchenQual','Functional','GarageFinish','GarageQual', 'GarageCond',\\\n",
    "'PavedDrive','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','ScreenPorch', \\\n",
    "'PoolArea', 'MiscVal','MoSold', 'YrSold','SaleType','SaleCondition'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic EDA for target variable\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.boxplot(y)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(y,bins=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.min(),y.mean(),y.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any error in houses with high saleprice\n",
    "house[house['SalePrice'] > 600000].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** <font color='purple'> target variable seems fine.. </font> **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segregate by continuous vs categorical features\n",
    "quant_features = X.select_dtypes(exclude='object').drop('MSSubClass',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quant_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for null values\n",
    "plt.figure(figsize=(12,3))\n",
    "sns.heatmap(quant_features.isnull(),yticklabels=False,cbar=False,cmap='viridis') #for checking null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X[X.columns[~X.columns.isin(quant_features.columns)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,3))\n",
    "sns.heatmap(cat_features.isnull(),yticklabels=False,cbar=False,cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bi-variate EDA\n",
    "quant_plot = pd.melt(quant_features.join(y),id_vars='SalePrice')\n",
    "g = sns.FacetGrid(quant_plot, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "g = g.map(sns.regplot, 'value','SalePrice', line_kws={'color':'red','linewidth':1.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Some plots (e.g. TotalBsmtSF, 1stFlrSF) look more y=x*2 then y=x : to KIV for subsequent model tuning\n",
    "    <br>- Some outliers for SF-related features (e.g LotFrontage, LotArea, BsmtFinSF1, 1stFlrSF) : also KIV first</font> \n",
    "\n",
    "<br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_plot = pd.melt(cat_features.join(y),id_vars='SalePrice')\n",
    "g = sns.FacetGrid(cat_plot, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "g = g.map(sns.barplot, 'value','SalePrice', palette='RdYlBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.barplot(x='SalePrice',y='Neighborhood',data=house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, LassoCV, ElasticNetCV\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train set to get values for imputation \n",
    "X_train = house[house['YrSold'] < 2010][X.columns]\n",
    "\n",
    "# check columns that have null values\n",
    "X_train.columns[X_train.isnull().apply(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get values (mean for quant features and mode for cat features)\n",
    "d = {}\n",
    "d['LotFrontage'] = X_train['LotFrontage'].mean()\n",
    "d['GarageYrBlt'] = round(X_train['GarageYrBlt'].mean(),0)\n",
    "d['GarageType'] = X_train['GarageType'].mode()[0]\n",
    "d['BsmtQual'] = X_train['BsmtQual'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an extra column to indicate rows with imputed values\n",
    "X_imp = X.copy()\n",
    "X_imp['is_imputed'] = X_imp.isnull().apply(sum,axis=1) #can use max for 1/0\n",
    "\n",
    "# imputing NA values\n",
    "for feature in ['LotFrontage', 'BsmtQual', 'GarageType', 'GarageYrBlt']:\n",
    "    X_imp[feature].fillna(d[feature],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies\n",
    "X_imp['MSSubClass'] = X_imp['MSSubClass'].apply(lambda x: str(x))\n",
    "X_imp = pd.get_dummies(X_imp,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "X_train = X_imp[house['YrSold'] < 2010]\n",
    "X_test = X_imp[house['YrSold'] >= 2010]\n",
    "y_train = house[house['YrSold'] < 2010]['SalePrice']\n",
    "y_test = house[house['YrSold'] >= 2010]['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "sX_train = scaler.transform(X_train)\n",
    "sX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, sX_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(lm, X_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_model = lm.fit(X_train,y_train)\n",
    "y_pred = lm_model.predict(X_test)\n",
    "metrics.mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_coefs = pd.DataFrame({'variable':X_train.columns, 'coef':lm_model.coef_, 'abs_coef':np.abs(lm_model.coef_)})\n",
    "lm_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "lm_coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opt_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opt_lasso.fit(sX_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=opt_lasso.alpha_)\n",
    "scores = cross_val_score(lasso, sX_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opt_lasso.fit(sX_train, y_train)\n",
    "\n",
    "opt_lasso.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(sX_train,y_train)\n",
    "y_pred = lasso.predict(sX_test)\n",
    "metrics.mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Lasso performs slightly better than LinearRegression\n",
    "    </font> \n",
    "  \n",
    "  <br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(sX_train, y_train)\n",
    "lasso_coefs = pd.DataFrame({'variable':X_train.columns, 'coef':lasso.coef_, 'abs_coef':np.abs(lasso.coef_)})\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "lasso_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratios = np.linspace(0.01, 1.0, 25) \n",
    "opt_enet = ElasticNetCV(l1_ratio=l1_ratios, n_alphas=100, cv=3)\n",
    "opt_enet.fit(sX_train, y_train)\n",
    "\n",
    "enet = ElasticNet(alpha=opt_enet.alpha_, l1_ratio=opt_enet.l1_ratio_)\n",
    "scores = cross_val_score(enet, sX_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - ElasticNet and Lasso similar output (i.e. opt_enet.l1_ratio_ = 1.0)\n",
    "    </font> \n",
    "  \n",
    "  <br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Further feature engineering and try to improve model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = list(lasso_coefs.head(20)['variable'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_plot = pd.melt(X_train[best_features].join(y),id_vars='SalePrice')\n",
    "g = sns.FacetGrid(quant_plot, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "g = g.map(sns.regplot, 'value','SalePrice', line_kws={'color':'red','linewidth':1.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "house.drop(house[house['GrLivArea'] > 4500].index,inplace=True)\n",
    "# from shape of scatterplot, log GrLivArea\n",
    "house['GrLivArea'] = np.log(house['GrLivArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house['TotalSF'] = house['TotalBsmtSF'] + house['1stFlrSF'] + house['2ndFlrSF']\n",
    "house.drop(['TotalBsmtSF','1stFlrSF','2ndFlrSF'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat all previous steps...\n",
    "\n",
    "X = house.drop(['Id','SalePrice'],axis=1)\n",
    "y = house['SalePrice']\n",
    "\n",
    "#dropping non-fixed features\n",
    "X.drop(['OverallQual', 'OverallCond','RoofStyle','RoofMatl', 'Exterior1st', 'Exterior2nd',\\\n",
    "'MasVnrType', 'MasVnrArea','ExterQual', 'ExterCond', 'BsmtCond', 'BsmtExposure',\\\n",
    "'BsmtFinType1', 'BsmtFinType2', 'BsmtUnfSF','Heating', 'HeatingQC','CentralAir',\\\n",
    "'Electrical', 'KitchenQual','Functional','GarageFinish','GarageQual', 'GarageCond',\\\n",
    "'PavedDrive','WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch','ScreenPorch', \\\n",
    "'PoolArea', 'MiscVal','MoSold', 'YrSold','SaleType','SaleCondition'],axis=1,inplace=True)\n",
    "\n",
    "#split data into train set to get values for imputation \n",
    "X_train = house[house['YrSold'] < 2010][X.columns]\n",
    "\n",
    "# check columns that have null values\n",
    "X_train.columns[X_train.isnull().apply(sum) > 0]\n",
    "\n",
    "# get values (mean for quant features and mode for cat features)\n",
    "d = {}\n",
    "d['LotFrontage'] = X_train['LotFrontage'].mean()\n",
    "d['GarageYrBlt'] = round(X_train['GarageYrBlt'].mean(),0)\n",
    "d['GarageType'] = X_train['GarageType'].mode()[0]\n",
    "d['BsmtQual'] = X_train['BsmtQual'].mode()[0]\n",
    "\n",
    "#creating an extra column to indicate rows with imputed values\n",
    "X_imp = X.copy()\n",
    "X_imp['is_imputed'] = X_imp.isnull().apply(sum,axis=1) \n",
    "\n",
    "# imputing NA values\n",
    "for feature in ['LotFrontage', 'BsmtQual', 'GarageType', 'GarageYrBlt']:\n",
    "    X_imp[feature].fillna(d[feature],inplace=True)\n",
    "\n",
    "#create dummies\n",
    "X_imp['MSSubClass'] = X_imp['MSSubClass'].apply(lambda x: str(x))\n",
    "X_imp = pd.get_dummies(X_imp,drop_first=True)\n",
    "\n",
    "#split train and test data\n",
    "X_train = X_imp[house['YrSold'] < 2010]\n",
    "X_test = X_imp[house['YrSold'] >= 2010]\n",
    "y_train = house[house['YrSold'] < 2010]['SalePrice']\n",
    "y_test = house[house['YrSold'] >= 2010]['SalePrice']\n",
    "\n",
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "sX_train = scaler.transform(X_train)\n",
    "sX_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opt_lasso.fit(sX_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=opt_lasso.alpha_)\n",
    "scores = cross_val_score(lasso, sX_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(sX_train,y_train)\n",
    "y_pred = lasso.predict(sX_test)\n",
    "metrics.mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_vars = pd.DataFrame({'variable':X_train.columns, 'coef':lasso.coef_, 'abscoef':np.abs(lasso.coef_)})\n",
    "coefs_vars.sort_values('abscoef', ascending=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sns.barplot(y='variable',x='coef',data=coefs_vars[0:30].sort_values('coef',ascending=False), palette='magma_r')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Better performance after feature engineering\n",
    "    </font> \n",
    "  \n",
    "  <br>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(house['TotalSF'],np.log(house['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested logging target variable based on above graph\n",
    "y_train = np.log(house[house['YrSold'] < 2010]['SalePrice'])\n",
    "y_test = np.log(house[house['YrSold'] >= 2010]['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opt_lasso.fit(sX_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=opt_lasso.alpha_)\n",
    "scores = cross_val_score(lasso, sX_train, y_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(sX_train,y_train)\n",
    "y_pred = lasso.predict(sX_test)\n",
    "metrics.mean_squared_error(np.exp(y_pred), np.exp(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Slight improvements\n",
    "    </font> \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.regplot(np.exp(y_pred),np.exp(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.exp(y_test)-np.exp(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Determine any value of *changeable* property characteristics unexplained by the *fixed* ones.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you have a model that estimates the price of a house based on its static characteristics, we can move forward with part 2 and 3 of the plan: what are the costs/benefits of quality, condition, and renovations?\n",
    "\n",
    "There are two specific requirements for these estimates:\n",
    "1. The estimates of effects must be in terms of dollars added or subtracted from the house value. \n",
    "2. The effects must be on the variance in price remaining from the first model.\n",
    "\n",
    "The residuals from the first model (training and testing) represent the variance in price unexplained by the fixed characteristics. Of that variance in price remaining, how much of it can be explained by the easy-to-change aspects of the property?\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Evaluate the effect in dollars of the renovate-able features. \n",
    "- How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have built to determine if they can make money. \n",
    "- Investigate how much of the variance in price remaining is explained by these features.\n",
    "- Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler.fit(X_train)\n",
    "lasso.fit(sX_train,y_train)\n",
    "y_pred = lasso.predict(scaler.transform(X_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_calc = pd.DataFrame(np.exp(y_pred), columns=['y_pred']).join(house['SalePrice'].reset_index(drop=True))\n",
    "res_calc['res'] = res_calc['SalePrice'] - res_calc['y_pred']\n",
    "y = res_calc['res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reno = house.columns[~house.columns.isin(X.columns)]\n",
    "reno = reno.drop(['Id','MoSold', 'YrSold', 'SaleType','SaleCondition', 'SalePrice'])\n",
    "reno = house[reno]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reno.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#reno_plot = pd.melt(reno.select_dtypes(exclude='object').join(y),id_vars='res')\n",
    "#g = sns.FacetGrid(reno_plot, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "#g = g.map(sns.distplot, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reno_plot = pd.melt(reno.select_dtypes(include='object'))\n",
    "#g = sns.FacetGrid(reno_plot, col='variable', col_wrap=4, sharex=False, sharey=False)\n",
    "#g = g.map(sns.countplot, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Large class inbalance observed in multiple features\n",
    "\n",
    "    </font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "sns.heatmap(reno.isnull(),yticklabels=False,cbar=False,cmap='viridis') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reno.columns[reno.isnull().apply(sum) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating null values\n",
    "\n",
    "#reno[reno['BsmtCond'].isnull()].transpose()\n",
    "#reno[reno['GarageQual'].isnull()].transpose()\n",
    "#reno[reno['MasVnrArea'].isnull()]\n",
    "house[reno['Electrical'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an extra column to indicate rows with imputed values\n",
    "reno_imp = reno.copy()\n",
    "reno_imp['is_imputed'] = reno_imp.isnull().apply(sum,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume that null values for Bsmt/Garage/MasVnr means houses don't have Bsmt/Garage/MasVnr\n",
    "\n",
    "for feature in ['MasVnrType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1',\\\n",
    "               'BsmtFinType2', 'GarageFinish', 'GarageQual','GarageCond']:\n",
    "    reno_imp[feature].fillna('None',inplace=True)\n",
    "    \n",
    "reno_imp['MasVnrArea'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute null electrical value with mode of 'train' set\n",
    "house[house['YrSold'] < 2010 ]['Electrical'].value_counts()\n",
    "reno_imp['Electrical'].fillna('SBrkr', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for any more null values \n",
    "reno_imp.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for misclassified/duplicated/weird feature categories\n",
    "for feature in reno_imp.select_dtypes(include='object').columns:\n",
    "    print (feature, reno_imp[feature].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reno_imp['BsmtExposure'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummies\n",
    "reno_imp = pd.get_dummies(reno_imp,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data\n",
    "reno_train = reno_imp[house['YrSold'] < 2010]\n",
    "reno_test = reno_imp[house['YrSold'] >= 2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some indexing issue so join res_calc and house df tgt first, then split train and test set\n",
    "res_calc.rename(columns={'SalePrice':'saleprice'},inplace=True)\n",
    "temp = res_calc.join(house.reset_index())\n",
    "res_train = temp[temp['YrSold'] < 2010]['res']\n",
    "res_test = temp[temp['YrSold'] >= 2010]['res']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(reno_train.shape, res_train.shape)\n",
    "print(reno_test.shape, res_test.shape)\n",
    "\n",
    "print(reno_train.isnull().any().any(), res_train.isnull().any())\n",
    "print(reno_test.isnull().any().any(), res_test.isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(reno_train)\n",
    "sreno_train = scaler.transform(reno_train)\n",
    "sreno_test = scaler.transform(reno_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opti_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opti_lasso.fit(sreno_train, res_train)\n",
    "\n",
    "res_lasso = Lasso(alpha=opti_lasso.alpha_)\n",
    "scores = cross_val_score(res_lasso, sreno_train, res_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_lasso.fit(sreno_train,res_train)\n",
    "res_pred = res_lasso.predict(sreno_test)\n",
    "metrics.mean_squared_error(res_pred, res_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Results are quite poor (i.e. renovate-able features cannot really explain variance from price remaining)\n",
    "\n",
    "    </font> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_vars = pd.DataFrame({'variable':reno_train.columns, 'coef':res_lasso.coef_, 'abscoef':np.abs(res_lasso.coef_)})\n",
    "coefs_vars.sort_values('abscoef', ascending=False, inplace=True)\n",
    "coefs_vars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Tried to remove features with large class inbalance\n",
    "\n",
    "    </font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drop = reno_train.columns[abs(reno_train.skew())>1]\n",
    "reno_train2 = reno_train.drop(drop, axis=1)\n",
    "reno_test2 = reno_test.drop(drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reno_train2.shape, reno_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(reno_train2)\n",
    "sreno_train2 = scaler.transform(reno_train2)\n",
    "sreno_test2 = scaler.transform(reno_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "opti_lasso = LassoCV(n_alphas=100, cv=3)\n",
    "opti_lasso.fit(sreno_train2, res_train)\n",
    "\n",
    "res_lasso = Lasso(alpha=opti_lasso.alpha_)\n",
    "scores = cross_val_score(res_lasso, sreno_train2, res_train, cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res_lasso.fit(sreno_train2,res_train)\n",
    "res_pred = res_lasso.predict(sreno_test2)\n",
    "metrics.mean_squared_error(res_pred, res_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "coefs_vars = pd.DataFrame({'variable':reno_train2.columns, \\\n",
    "                           'coef':res_lasso.coef_, 'abscoef':np.abs(res_lasso.coef_)})\n",
    "coefs_vars.sort_values('abscoef', ascending=False, inplace=True)\n",
    "coefs_vars.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "- R2 improved but MSE deproved -> not very effective\n",
    "\n",
    "    </font> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(house['OverallQual'], np.log(house['SalePrice']))\n",
    "sns.regplot(house['OverallCond'], np.log(house['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(house['OverallQual'], res_calc['res'])\n",
    "sns.regplot(house['OverallCond'], res_calc['res'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='purple'> \n",
    "    - Overall, the model developed in qn 1 (using fixed features) performs well and can predict prices accurately\n",
    "    <br>\n",
    "    - The model developed in qn 2 is less successful and can only explain the variance in price remaining from the first model marginally. With that said, OverallQual and OverallCond stills remains good predictors of residual value. \n",
    "\n",
    "    </font> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. What property characteristics predict an \"abnormal\" sale?\n",
    "\n",
    "---\n",
    "\n",
    "The `SaleCondition` feature indicates the circumstances of the house sale. From the data file, we can see that the possibilities are:\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
    "       \n",
    "One of the executives at your company has an \"in\" with higher-ups at the major regional bank. His friends at the bank have made him a proposal: if he can reliably indicate what features, if any, predict \"abnormal\" sales (foreclosures, short sales, etc.), then in return the bank will give him first dibs on the pre-auction purchase of those properties (at a dirt-cheap price).\n",
    "\n",
    "He has tasked you with determining (and adequately validating) which features of a property predict this type of sale. \n",
    "\n",
    "---\n",
    "\n",
    "**Your task:**\n",
    "1. Determine which features predict the `Abnorml` category in the `SaleCondition` feature.\n",
    "- Justify your results.\n",
    "\n",
    "This is a challenging task that tests your ability to perform classification analysis in the face of severe class imbalance. You may find that simply running a classifier on the full dataset to predict the category ends up useless: when there is bad class imbalance classifiers often tend to simply guess the majority class.\n",
    "\n",
    "It is up to you to determine how you will tackle this problem. I recommend doing some research to find out how others have dealt with the problem in the past. Make sure to justify your solution. Don't worry about it being \"the best\" solution, but be rigorous.\n",
    "\n",
    "Be sure to indicate which features are predictive (if any) and whether they are positive or negative predictors of abnormal sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house['SaleCondition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "96/house.count().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = house.copy()\n",
    "nfeatures = df.columns[df[df['SaleCondition'] == 'Abnorml'].isnull().any()]\n",
    "nfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "sns.heatmap(df[df['SaleCondition'] == 'Abnorml'].isnull()[nfeatures],yticklabels=False,cbar=False,cmap='viridis') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assume that null values for Bsmt/Garage/MasVnr means houses don't have Bsmt/Garage/MasVnr\n",
    "for feature in ['BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1','BsmtFinType2',\\\n",
    "                'GarageType','GarageFinish','GarageQual', 'GarageCond']:\n",
    "    df[feature].fillna('None',inplace=True)\n",
    "\n",
    "df['GarageYrBlt'].fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Log Regression model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Random Over-Sampling\n",
    "Cluster-Based Over Sampling (K-means clustering algorithm)\n",
    "Informed Over Sampling: Synthetic Minority Over-sampling Technique (SMOTE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
